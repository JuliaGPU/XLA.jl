{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [`XLA.jl`](https://github.com/JuliaTPU/XLA.jl): ResNet on TPUs - Introduction\n",
    "\n",
    "In this notebook, we will step through the fundamental infrastructure necessary to load a [ResNet50](https://arxiv.org/abs/1512.03385) model, JIT it for the [TPU](https://en.wikipedia.org/wiki/Tensor_processing_unit), and feed it with some data in order to get classifications out.  Once you are comfortable with this material, you may wish to move on to [simple model training on the TPU](2_ResNet_Training.ipynb), followed by [distributed TPU training](3_ResNet_DistributedTraining.ipynb).\n",
    "\n",
    "## Overview of `XLA.jl` workflow\n",
    "\n",
    "We will define a model in plain Julia using the [`Flux.jl`](https://github.com/FluxML/Flux.jl) framework, that will provide the ResNet 50 model computation.  The model definition is contained within the file [`resnet50.jl`](resnet50.jl), however note that in the near future this will instead be sourced from the Metalhead.jl repository of general computer vision models defined in `Flux.jl`/Julia.\n",
    "\n",
    "We will define a simple set of mappings to convert a standard Julia model to be TPU-runnable.  There are a number of restrictions within the current XLA.jl compiler that must be adhered to for compilation to succeed:\n",
    "\n",
    "* All arrays and scalars must be of type `XRTArray` and must have an element type of `Float32`, including literals.  This unfortunately means that code such as `1./x` must be transformed to `XRTArray(1f0)./x`.  We intend to make this an automatic process in the future, but for the time being we manually define the appropriate helper functions such as `softmax()` that use `XRTArray`'s properly within [`model_utils.jl`](model_utils.jl).\n",
    "\n",
    "* All arrays are immutable, meaning that the definition of some layers such as Batch Normalization in `Flux.jl` must be adapted.  We have created two separate versions of the `BatchNorm` layer in this repository, one meant to be used on the [TPU](tpu_batch_norm.jl) (which we will be using here) and one on the [CPU](cpu_batch_norm.jl), for testing and verification.\n",
    "\n",
    "We will now load in the necessary packages, instantiating an environment local to these notebooks, and construct the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General`\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m git-repo `https://github.com/JuliaRegistries/General.git`\n",
      "\u001b[?25l\u001b[2K\u001b[?25h"
     ]
    }
   ],
   "source": [
    "# Load package versions that are known to work with TPUs, check that Julia version is a known compatible one\n",
    "if Base.GIT_VERSION_INFO.commit != \"f1dffc5c8b6b7f960b5e30835631b4caf4434b04\"\n",
    "    @warn(\"Only the very latest Julia version on the `kf/tpu3` branch is supported!\")\n",
    "end\n",
    "\n",
    "import Pkg\n",
    "Pkg.activate(@__DIR__)\n",
    "Pkg.instantiate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Recompiling stale cache file /home/sabae/.julia/compiled/v1.1/TensorFlow/IhIhf.ji for TensorFlow [1d978283-2c37-5f34-9a8e-e9c0ece82495]\n",
      "└ @ Base loading.jl:1184\n",
      "┌ Warning: Loading a new version of TensorFlow.jl for the first time. This initial load can take around 5 minutes as code is precompiled; subsequent usage will only take a few seconds.\n",
      "└ @ TensorFlow ~/.julia/packages/TensorFlow/eu9qM/src/TensorFlow.jl:3\n",
      "┌ Warning: Package TensorFlow does not have Pkg in its dependencies:\n",
      "│ - If you have TensorFlow checked out for development and have\n",
      "│   added Pkg as a dependency but haven't updated your primary\n",
      "│   environment's manifest file, try `Pkg.resolve()`.\n",
      "│ - Otherwise you may need to report an issue with TensorFlow\n",
      "└ Loading Pkg into TensorFlow from project dependency, future warnings for TensorFlow are suppressed.\n",
      "┌ Info: Precompiling XLA [1ae4bca4-de81-11e8-0eca-6d3e4e7c4181]\n",
      "└ @ Base loading.jl:1186\n",
      "WARNING: could not import xla.Shape into XLA\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Initialized ResNet50 model with 25583464 learnable parameters\n"
     ]
    }
   ],
   "source": [
    "# Load in packages and model definition\n",
    "using TensorFlow, XLA, Flux, Printf\n",
    "include(\"resnet50.jl\")\n",
    "include(\"tpu_batch_norm.jl\")\n",
    "\n",
    "model = resnet50();\n",
    "println(\"=> Initialized ResNet50 model with $(sum(prod(size(p)) for p in params(model))) learnable parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we have a `Flux.jl` ResNet50 model.  The next thing we need to do is to alter the model such that it is compileable via `XLA.jl`.  We will do so by defining a set of mapping functions that take advantage of multiple dispatch to recursively walk the model structure, converting normal arrays to `XRTArray`s, coercing scalar values to `Float32`, and converting `BatchNorm` layers to `TPUBatchNorm` objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Mapped model to TPU-specific construction\n"
     ]
    }
   ],
   "source": [
    "# Convert scalars to single-element XRTArrays with eltype Float32:\n",
    "map_to_tpu(x::Real) = XRTArray(convert(Float32, x))\n",
    "\n",
    "# Convert arrays to XRTArrays with eltype Float32\n",
    "map_to_tpu(x::AbstractArray) = XRTArray(Float32.(x))\n",
    "\n",
    "# Strip off the TrackedArray coating to get at the data underneath\n",
    "map_to_tpu(x::TrackedArray) = map_to_tpu(Flux.data(x))\n",
    "\n",
    "# Turn Chain objects into ImmutableChain objects which store the computation within their type signature\n",
    "map_to_tpu(x::Chain) = ImmutableChain(tuple(map(map_to_tpu, x.layers)...))\n",
    "\n",
    "# Convert BatchNorm layers into TPUBatchNorm layers, passing all children straight through,\n",
    "# except for the \"active\" child, which is not used by the TPUBatchNorm\n",
    "map_to_tpu(x::BatchNorm) = TPUBatchNorm(map(map_to_tpu, Flux.children(x))[1:end-1]...)\n",
    "\n",
    "# For all other objects, just map the children through `map_to_tpu`.\n",
    "map_to_tpu(x) = Flux.mapchildren(map_to_tpu, x)\n",
    "\n",
    "\n",
    "# Convert our model to the TPU-compatible version\n",
    "tpu_model = map_to_tpu(model)\n",
    "println(\"=> Mapped model to TPU-specific construction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling the model\n",
    "\n",
    "At this point, we are ready to compile the model.  In order to do so, we must first connect to a TPU or `xrt_server` binary running on a host.  We will connect here to a TPU running on a certain port, and assign the special global variable name `sess` to a `Session` object.  Once we have connected to the TPU, we can use the `@tpu_compile` macro to compile our model down to an executable handle which can then be invoked to actually run the computation upon an `x`.\n",
    "\n",
    "Compilation can take quite a while.  On the GCE machine this notebook was run on, the first compilation took over 30 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to TPU on 10.240.7.3\n",
      "=> Compiled model in 37.8 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-25 08:42:33.562811: W tensorflow/core/distributed_runtime/rpc/grpc_session.cc:349] GrpcSession::ListDevices will initialize the session with an empty graph and other defaults because the session has not yet been created.\n"
     ]
    }
   ],
   "source": [
    "tpu_ip = \"10.240.7.3\"\n",
    "println(\"Connecting to TPU on $(tpu_ip)\")\n",
    "\n",
    "# NOTE: If you are connecting to an actual TPU, use `TPUSession`.  If you are\n",
    "# connecting to an `xrt_server`, use `Session()`.\n",
    "sess = TPUSession(\"$(tpu_ip):8470\")\n",
    "#sess = Session(Graph(); target=\"grpc://$(tpu_ip):8470\")\n",
    "\n",
    "# Generate random input tensor; a batch of two images with spatial dimensions 224x224 and 3 color channels.\n",
    "x = randn(Float32, 224, 224, 3, 2)\n",
    "\n",
    "# Compile the model\n",
    "t_start = time()\n",
    "compilation_handle = @tpu_compile tpu_model(XRTArray(x));\n",
    "t_end = time()\n",
    "\n",
    "println(@sprintf(\"=> Compiled model in %.1f seconds\", t_end - t_start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that it is compiled, we can run it using `TensorFlow.jl`'s `run()` method.  We must pass first the compilation handle, then a structure containing the weights of the model, then the tensor to be pushed through the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000×2 Array{Float32,2}:\n",
       " -3.08357e-5  -3.44143e-5\n",
       " -2.50667e-5  -2.82241e-5\n",
       "  4.68369e-5   4.97169e-5\n",
       "  1.55978e-5   1.5855e-5 \n",
       " -2.10058e-5  -1.73037e-5\n",
       " -2.55337e-5  -3.1126e-5 \n",
       "  2.59295e-5   2.49413e-5\n",
       "  8.43253e-5   8.75408e-5\n",
       "  2.35524e-5   2.1518e-5 \n",
       " -8.96309e-5  -8.57574e-5\n",
       " -2.83913e-5  -2.54157e-5\n",
       "  4.84452e-5   4.66785e-5\n",
       " -5.6611e-5   -6.31944e-5\n",
       "  ⋮                      \n",
       " -7.0416e-5   -6.48332e-5\n",
       "  3.08008e-5   3.16662e-5\n",
       "  8.73816e-6   1.04928e-5\n",
       "  3.26924e-5   3.338e-5  \n",
       "  1.19472e-5   1.10719e-5\n",
       "  2.35837e-5   2.41352e-5\n",
       "  2.20582e-5   2.06743e-5\n",
       " -3.8227e-5   -4.37534e-5\n",
       "  6.43322e-5   6.40988e-5\n",
       "  7.51983e-5   7.59495e-5\n",
       "  1.96773e-5   1.95593e-5\n",
       " -6.42807e-5  -6.31979e-5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "error in running finalizer: ErrorException(\"type TPUSession has no field ptr\")\n"
     ]
    }
   ],
   "source": [
    "# Run the actual computation\n",
    "y_hat = run(compilation_handle,\n",
    "    # Transfer model weights\n",
    "    XRTRemoteStruct(sess, tpu_model),\n",
    "    # Transfer `x`\n",
    "    XRTArray(sess, x)\n",
    ")\n",
    "\n",
    "# Convert the output (which is an XRTArray) back to a normal array:\n",
    "y_hat = convert(Array, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And just like that, you have successfully translated, compiled, and run your first model on the TPU.  Congratulations!  You should feel very proud of yourself.  Next up, we will learn to do some training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": "e1d31cf6583644a49f43a6f27c35d0f5",
   "lastKernelId": "ba2392c3-d184-45e5-9467-584a54c9472a"
  },
  "kernelspec": {
   "display_name": "Julia 1.1.0-DEV",
   "language": "julia",
   "name": "julia-1.1"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
